---
title: "Homework_2"
output: html_document
date: "2025-02-17"
---

## I. Multiple Linear Regression: Matrix Representation

### 2. Write an R function that takes the vector Y and matrix X as input then calculates and returns esimtations paramaters of interest  

```{r}
Y <- c(-0.1, 2.9, 6.2, 7.3, 10.7)
X <- matrix(c(1, 1, 1, 1, 1, 1, 3, 5, 7, 9), nrow=5, ncol=2)
matrix_linear_reg <- function(Y,X) {
  # a. least squares estimates of the regression coefficients
  beta_hat <- solve(t(X) %*% X) %*% t(X) %*% Y
  # b. the residual mean squared error
 # resid_mse <- sum((Y - X%*%beta_hat)^2) / (length(Y) - ncol(X))
  resid_mse <- (t(Y - X%*%beta_hat) %*% (Y - X%*%beta_hat)) / 
    (length(Y) - ncol(X))
  # c. the variance-covariance matrix of the least squares estiamtes
  resid_mse_bias <- sum((Y - X%*%beta_hat)^2) / length(Y)
  varcovar <- resid_mse_bias * solve(t(X) %*% X)
  # d. the vector of predicted values 
  predicted_values <- X %*% solve(t(X)%*%X) %*% t(X) %*% Y
  # e. vector of residuals
  residuals <- (diag(length(Y)) - (X %*% solve(t(X)%*%X) %*% t(X))) %*% Y
  return(list(Regression_Coef_Estimates = beta_hat, 
              Residual_Mean_Square_Error = resid_mse, 
              Variance_Covariance_Matrix = varcovar, 
              Predicted_Values = predicted_values, Residuals = residuals)) 
}
matrix_linear_reg(Y,X)
```

### 3. Using the R function from Question 2, verify your estimates of the simple linear regression intercept, slope and residual mean squared error computed in Question 1.  

The estimates of the simple linear regression intercept, slope, and residual mean squared error are the same in part 1 and part 2.
write beta hat in latex

$\hat{\beta_0} = -1.1$  
$\hat{\beta_1} = 1.3$
$\tilde{\sigma^2} = 0.413$  

## II. Properties and behaviors of MLR coefficients  

### 1. Impact of gaussian residual assumption on the distribution of beta_j for j = 1, 2.  

### a. Write an R function that takes an input n and genearates estimates for beta based on the model  

Using provided code:  
```{r}
my.sim = function(n = 100){
  ## Generate X1 
  X1 = rexp(n, rate = 5)
  ## Generate X2
  X2 = 0.2 * X1 + rnorm(n,mean=0,sd=0.2)
  ## Generate Y
  y = 1.5 + 1 * X1 - 0.25 * X2 + scale(rchisq(n,df=2))
  ##
  ## After the above commands, you have simulated
  ## the sample of size n with data (y, X1, X2)
  ##
  ## Fit the MLR
  fit = lm(y~X1 + X2)
  ## Return beta-hat-j for j = 1 and 2
  fit$coefficients[2:3]
}
```

### b. For n =100, run your R function at least 1,000 times and create plots for beta_j  

```{r}
set.seed(12345)

## Set K = 1000
K = 1000

## You can use a for loop
slopes = NULL
for(i in 1:K) slopes = cbind(slopes,my.sim(n = 100))
summary(t(slopes))

# Histogram and Normal Probability Plot for Beta 1
hist(t(slopes)[,1], main = expression(paste("Histogram of ", hat(beta[1]))), xlab = expression(hat(beta[1])), ylab = "Frequency", col = "lightblue", border = "black")
qqnorm(t(slopes)[,1], main = expression(paste("Normal Probability Plot of ", hat(beta[1]))))

# Histogram and Normal Probability Plot for Beta 2
hist(t(slopes)[,2], main = expression(paste("Histogram of ", hat(beta[2]))), xlab = expression(hat(beta[2])), ylab = "Frequency", col = "lightblue", border = "black")
qqnorm(t(slopes)[,2], main = expression(paste("Normal Probability Plot of ", hat(beta[2]))))
```

By looking at the histograms and normal probability plots for $\hat{\beta_1}$ and $\hat{\beta_2}$, we can see that the sampling distributions for $\hat{\beta_1}$ and $\hat{\beta_2}$ are approximately normal because the histograms show a bell-shaped curve and the normal probability plots show a linear relationship between the theoretical and sample quantiles.  

### c. Reduce the sample size to n = 15. Comment on any differences you observe in the sampling distribution for beta_j for j = 1, 2 when n = 100 vs. n = 15.  

```{r}
set.seed(56)
slopes_15 = NULL
for(i in 1:K) slopes_15 = cbind(slopes_15,my.sim(n = 15))
summary(t(slopes_15))

# Histogram and Normal Probability Plot for Beta 1
hist(t(slopes_15)[,1], main = expression(paste("Histogram of ", hat(beta[1]))), xlab = expression(hat(beta[1])), ylab = "Frequency", col = "lightblue", border = "black")
qqnorm(t(slopes_15)[,1], main = expression(paste("Normal Probability Plot of ", hat(beta[1]))))

# Histogram and Normal Probability Plot for Beta 2
hist(t(slopes_15)[,2], main = expression(paste("Histogram of ", hat(beta[2]))), xlab = expression(hat(beta[2])), ylab = "Frequency", col = "lightblue", border = "black")
qqnorm(t(slopes_15)[,2], main = expression(paste("Normal Probability Plot of ", hat(beta[2]))))
```

